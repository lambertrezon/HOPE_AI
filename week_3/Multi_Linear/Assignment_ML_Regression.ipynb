{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3nQn1aHlvX3zh90MniZtE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Required libs\n","import pandas as pd\n","import numpy as np\n","from itertools import product\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import r2_score\n","\n","# Dataset\n","dataset_path = \"/content/gdrive/MyDrive/Colab Notebooks/Copy of 50_Startups.csv\"\n","\n","dataset = pd.read_csv(dataset_path)\n","dataset = pd.get_dummies(dataset, drop_first=True)  # One-hot encode categorical columns\n","\n","# Independent & Dependent variables declartion\n","X = dataset[['R&D Spend', 'Administration', 'Marketing Spend', 'State_Florida', 'State_New York']]\n","y = dataset[['Profit']]\n","\n","# Train/Test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n","\n","# MLR\n","from sklearn.linear_model import LinearRegression\n","\n","lr = LinearRegression()\n","lr.fit(X_train, y_train)\n","r2_lr = r2_score(y_test, lr.predict(X_test))\n","print(f\"\\nMULTIPLE LINEAR REGRESSION  →  R² = {r2_lr:.4f}\")\n","\n","#SVM\n","from sklearn.svm import SVR\n","\n","sc = StandardScaler()\n","X_train_svm = sc.fit_transform(X_train)\n","X_test_svm = sc.transform(X_test)\n","\n","#comomn c_value parameter\n","#commong kernels for all\n","C_values = [10, 100, 500, 1000, 2000, 3000]\n","kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n","\n","#loop\n","svm_results = []\n","for C, kernel in product(C_values, kernels):\n","    reg = SVR(C=C, kernel=kernel)\n","    reg.fit(X_train_svm, y_train.values.ravel())\n","    r2 = r2_score(y_test, reg.predict(X_test_svm))\n","    svm_results.append([C, kernel, r2])\n","\n","svm_df = pd.DataFrame(svm_results, columns=[\"C\", \"Kernel\", \"R²\"])\n","print(\"\\nSUPPORT VECTOR MACHINE RESULTS\")\n","print(svm_df.pivot(index=\"C\", columns=\"Kernel\", values=\"R²\").round(4))\n","\n","best_svm = svm_df.loc[svm_df['R²'].idxmax()]\n","print(f\"Best SVM: C={best_svm.C}, Kernel={best_svm.Kernel}, R²={best_svm['R²']:.4f}\")\n","\n","# Decision tree\n","from sklearn.tree import DecisionTreeRegressor\n","\n","criteria = ['squared_error', 'absolute_error', 'friedman_mse']\n","max_features = ['sqrt', 'log2']\n","splitters = ['best', 'random']\n","\n","dt_results = []\n","for crit, feat, split in product(criteria, max_features, splitters):\n","    reg = DecisionTreeRegressor(criterion=crit, splitter=split, max_features=feat, random_state=0)\n","    reg.fit(X_train, y_train)\n","    r2 = r2_score(y_test, reg.predict(X_test))\n","    dt_results.append([crit, feat, split, r2])\n","\n","dt_df = pd.DataFrame(dt_results, columns=['Criterion', 'Max_Features', 'Splitter', 'R²'])\n","print(\"\\nDECISION TREE RESULTS\")\n","print(dt_df.pivot_table(index=['Criterion', 'Max_Features'], columns='Splitter', values='R²').round(4))\n","\n","best_dt = dt_df.loc[dt_df['R²'].idxmax()]\n","print(f\"Best Decision Tree: {best_dt.to_dict()}\")\n","\n","#Random forest\n","from sklearn.ensemble import RandomForestRegressor\n","\n","criteria = ['squared_error', 'absolute_error']\n","\n","max_features = ['sqrt', 'log2']\n","n_estimators = [10, 100]\n","\n","rf_results = []\n","for crit, feat, n in product(criteria, max_features, n_estimators):\n","    reg = RandomForestRegressor(criterion=crit, max_features=feat, n_estimators=n, random_state=0)\n","    reg.fit(X_train, y_train.values.ravel())\n","    r2 = r2_score(y_test, reg.predict(X_test))\n","    rf_results.append([crit, feat, n, r2])\n","\n","rf_df = pd.DataFrame(rf_results, columns=['Criterion', 'Max_Features', 'N_Estimators', 'R²'])\n","print(\"\\nRANDOM FOREST RESULTS\")\n","print(rf_df.pivot_table(index=['Criterion', 'Max_Features'], columns='N_Estimators', values='R²').round(4))\n","\n","best_rf = rf_df.loc[rf_df['R²'].idxmax()]\n","print(f\"Best Random Forest: {best_rf.to_dict()}\")\n","\n","# SUMMARY OF ALL MODELS\n","summary = pd.DataFrame([\n","    ['Multiple Linear Regression', r2_lr],\n","    ['SVM (Best)', best_svm['R²']],\n","    ['Decision Tree (Best)', best_dt['R²']],\n","    ['Random Forest (Best)', best_rf['R²']]\n","], columns=['Model', 'Best R²'])\n","\n","print(\"\\n FINAL SUMMARY\")\n","print(summary)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"igTGtvDkp5xe","executionInfo":{"status":"ok","timestamp":1762345385719,"user_tz":-330,"elapsed":24886,"user":{"displayName":"Rezon Lambert","userId":"09998494782697120673"}},"outputId":"8b7b6632-7a17-4661-c525-ef09fa0ec9d6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","\n","MULTIPLE LINEAR REGRESSION  →  R² = 0.8753\n","\n","SUPPORT VECTOR MACHINE RESULTS\n","Kernel  linear    poly     rbf  sigmoid\n","C                                      \n","10     -0.1069 -0.1216 -0.1253  -0.1228\n","100     0.0430 -0.0842 -0.1208  -0.0964\n","500     0.5352  0.0718 -0.1015   0.0065\n","1000    0.7943  0.2113 -0.0800   0.1377\n","2000    0.8703  0.4921 -0.0306   0.3607\n","3000    0.8584  0.6603  0.0193   0.4987\n","Best SVM: C=2000, Kernel=linear, R²=0.8703\n","\n","DECISION TREE RESULTS\n","Splitter                       best  random\n","Criterion      Max_Features                \n","absolute_error log2         -0.0575  -0.561\n","               sqrt         -0.0575  -0.561\n","friedman_mse   log2          0.7282  -0.951\n","               sqrt          0.7282  -0.951\n","squared_error  log2          0.7282  -0.951\n","               sqrt          0.7282  -0.951\n","Best Decision Tree: {'Criterion': 'squared_error', 'Max_Features': 'sqrt', 'Splitter': 'best', 'R²': 0.728249856755945}\n","\n","4️⃣ RANDOM FOREST RESULTS\n","N_Estimators                    10      100\n","Criterion      Max_Features                \n","absolute_error log2          0.7688  0.8017\n","               sqrt          0.7688  0.8017\n","squared_error  log2          0.7393  0.7781\n","               sqrt          0.7393  0.7781\n","➡️ Best Random Forest: {'Criterion': 'absolute_error', 'Max_Features': 'sqrt', 'N_Estimators': 100, 'R²': 0.8017216588792825}\n","\n","✅ FINAL SUMMARY\n","                        Model   Best R²\n","0  Multiple Linear Regression  0.875266\n","1                  SVM (Best)  0.870257\n","2        Decision Tree (Best)  0.728250\n","3        Random Forest (Best)  0.801722\n"]}]}]}